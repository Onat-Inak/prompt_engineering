{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "hf_token  = os.getenv('HF_TOKEN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=hf_token,\n",
    ")\n",
    "\n",
    "stopping_ids = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOCAL LLAMA3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/onatinak/anaconda3/envs/prompt_engineering/lib/python3.9/site-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affb19420e924889a1570f9f205f15bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some parameters are on the meta device device because they were offloaded to the cpu and disk.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# Optional quantization to 4bit\n",
    "# from transformers import BitsAndBytesConfig\n",
    "\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#     load_in_4bit=True,\n",
    "#     bnb_4bit_compute_dtype=torch.float16,\n",
    "#     bnb_4bit_quant_type=\"nf4\",\n",
    "#     bnb_4bit_use_double_quant=True,\n",
    "# )\n",
    "\n",
    "# llm = HuggingFaceLLM(\n",
    "#     model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#     model_kwargs={\n",
    "#         \"token\": hf_token,\n",
    "#         \"torch_dtype\": torch.bfloat16,  # comment this line and uncomment below to use 4bit\n",
    "#         # \"quantization_config\": quantization_config\n",
    "#     },\n",
    "#     generate_kwargs={\n",
    "#         \"do_sample\": True,\n",
    "#         \"temperature\": 0.6,\n",
    "#         \"top_p\": 0.9,\n",
    "#     },\n",
    "#     tokenizer_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "#     tokenizer_kwargs={\"token\": hf_token},\n",
    "#     stopping_ids=stopping_ids,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE HF INFERENCE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_91837/4255368163.py:5: DeprecationWarning: Call to deprecated class HuggingFaceInferenceAPI. (Deprecated in favor of `HuggingFaceInferenceAPI` from `llama-index-llms-huggingface-api` which should be used instead.)\n",
      "  llm = HuggingFaceInferenceAPI(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## You can deploy the model on HF Inference Endpoint and use it\n",
    "\n",
    "from llama_index.llms.huggingface import HuggingFaceInferenceAPI\n",
    "\n",
    "llm = HuggingFaceInferenceAPI(\n",
    "    model_name=\"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
    "    token=hf_token\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A simple recipe for beginners\n",
      "Making a cake is a fun and rewarding process, and with this simple recipe, you can create a delicious and moist cake that's perfect for any occasion. Here's a step-by-step guide to making a cake for beginners:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 2 cups all-purpose flour\n",
      "* 1 teaspoon baking powder\n",
      "* 1 teaspoon baking soda\n",
      "* 1 teaspoon salt\n",
      "* 1 cup granulated sugar\n",
      "* 1/2 cup unsalted butter, softened\n",
      "* 2 large eggs\n",
      "* 2 teaspoons vanilla extract\n",
      "* 1 cup whole milk, at room temperature\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Preheat your oven to 350°F (180°C). Grease two 9-inch (23cm) round cake pans and line the bottoms with parchment paper.\n",
      "2. In a medium-sized bowl, whisk together the flour, baking powder, baking soda, and salt. Set aside.\n",
      "3. In a large mixing bowl, use an electric mixer to cream together the sugar and butter until light and fluffy, about 2-3 minutes.\n",
      "4. Beat in the eggs one at a time, allowing each egg to fully incorporate before adding the next. Beat in the vanilla extract.\n",
      "5. With the mixer on low speed, gradually\n"
     ]
    }
   ],
   "source": [
    "response = llm.complete(\"How to make a cake?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_URL = \"https://api-inference.huggingface.co/models/meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "headers = {\"Authorization\": \"Bearer \" + hf_token}\n",
    "\n",
    "def query(payload):\n",
    "\tresponse = requests.post(API_URL, headers=headers, json=payload)\n",
    "\treturn response.json()\n",
    "\t\n",
    "output = query({\n",
    "\t\"inputs\": \"Can you please let us know more details about your \",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Can you please let us know more details about your 1/4 BHK we have list in HMT Colony, Bangalore? Like the price, facility and other details we need more information to improve our knowledge about the property.\\nThanks for reaching out. The 1/4 BHK we have listed in HMT Colony, Bangalore is a compact and cozy apartment that offers a comfortable living space. Here are the details:\\n\\n**Price:** ₹25 lakhs to ₹28 lakhs (negotiable)\\n**Location:** HMT Colony, Bangalore\\n'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
